{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97d3321-4427-4837-8269-048dc64686f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from feature_eng.scalers import ranged_scaler\n",
    "from datetime import datetime, timedelta\n",
    "#from mpge.rca import mpge_root_cause_diagnosis\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "# Or if you are using > Python 3.11:\n",
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ef600a-406e-456a-98ac-8388b03ccc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec413833-9dbd-45bb-99a1-18e31bd014fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkgngc.embeddings import PretrainedTKGEmbeddingWithTimestamps\n",
    "from tkgngc.data_processing import TKGNGCDataProcessor\n",
    "from tkgngc.model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6981e0a1-e1c0-409d-ab6a-cf7d34bf1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = pl.read_csv(\"data/data.csv\", separator=\",\")  \n",
    "metadata = pl.read_csv('data/metadata.csv',separator=',')\n",
    "potential_causes = metadata['root_cause'].unique().to_list()\n",
    "\n",
    "for col in cats_df.columns:\n",
    "    unique_vals = cats_df[col].n_unique()\n",
    "    data_type = cats_df[col].dtype\n",
    "    bad_dtypes = [pl.Date,pl.Datetime,pl.Utf8]\n",
    "    if ((unique_vals >= 50) & (data_type not in bad_dtypes) ):\n",
    "        cats_df = cats_df.with_columns(ranged_scaler(cats_df[col]))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0f5a4d-1cf3-4a87-a3fb-751607296c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = cats_df.with_columns(\n",
    "    pl.col('timestamp').str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    pl.Series(\"entity_id\",range(len(cats_df)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b9af15-9315-41d4-86fe-907430746a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>aimp</th><th>amud</th><th>arnd</th><th>asin1</th><th>asin2</th><th>adbr</th><th>adfl</th><th>bed1</th><th>bed2</th><th>bfo1</th><th>bfo2</th><th>bso1</th><th>bso2</th><th>bso3</th><th>ced1</th><th>cfo1</th><th>cso1</th><th>y</th><th>category</th><th>entity_id</th></tr><tr><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>2023-01-01 00:00:00</td><td>0.0</td><td>0.571429</td><td>0.25</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.33599</td><td>0.315382</td><td>0.130919</td><td>0.116409</td><td>0.409726</td><td>0.246024</td><td>0.14197</td><td>0.112819</td><td>0.550194</td><td>0.406688</td><td>0.0</td><td>0.0</td><td>0</td></tr><tr><td>2023-01-01 00:00:01</td><td>0.0</td><td>0.571429</td><td>0.252001</td><td>0.50001</td><td>0.5001</td><td>0.0</td><td>0.0</td><td>0.33599</td><td>0.315382</td><td>0.130919</td><td>0.116409</td><td>0.40973</td><td>0.246024</td><td>0.14197</td><td>0.112819</td><td>0.550194</td><td>0.406691</td><td>0.0</td><td>0.0</td><td>1</td></tr><tr><td>2023-01-01 00:00:02</td><td>0.0</td><td>0.571429</td><td>0.256914</td><td>0.50002</td><td>0.5002</td><td>0.0</td><td>0.0</td><td>0.33599</td><td>0.315382</td><td>0.130919</td><td>0.116409</td><td>0.409741</td><td>0.246024</td><td>0.14197</td><td>0.112819</td><td>0.550195</td><td>0.406698</td><td>0.0</td><td>0.0</td><td>2</td></tr><tr><td>2023-01-01 00:00:03</td><td>0.0</td><td>0.571429</td><td>0.268273</td><td>0.50003</td><td>0.5003</td><td>0.0</td><td>0.0</td><td>0.33599</td><td>0.315382</td><td>0.130919</td><td>0.116409</td><td>0.409758</td><td>0.246024</td><td>0.14197</td><td>0.112819</td><td>0.550195</td><td>0.40671</td><td>0.0</td><td>0.0</td><td>3</td></tr><tr><td>2023-01-01 00:00:04</td><td>0.0</td><td>0.571429</td><td>0.277953</td><td>0.50004</td><td>0.5004</td><td>0.0</td><td>0.0</td><td>0.33599</td><td>0.315382</td><td>0.130919</td><td>0.116409</td><td>0.409782</td><td>0.246024</td><td>0.14197</td><td>0.112819</td><td>0.550197</td><td>0.406726</td><td>0.0</td><td>0.0</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌─────────────────────┬──────┬──────────┬──────────┬───┬──────────┬─────┬──────────┬───────────┐\n",
       "│ timestamp           ┆ aimp ┆ amud     ┆ arnd     ┆ … ┆ cso1     ┆ y   ┆ category ┆ entity_id │\n",
       "│ ---                 ┆ ---  ┆ ---      ┆ ---      ┆   ┆ ---      ┆ --- ┆ ---      ┆ ---       │\n",
       "│ datetime[μs]        ┆ f64  ┆ f64      ┆ f64      ┆   ┆ f64      ┆ f64 ┆ f64      ┆ i64       │\n",
       "╞═════════════════════╪══════╪══════════╪══════════╪═══╪══════════╪═════╪══════════╪═══════════╡\n",
       "│ 2023-01-01 00:00:00 ┆ 0.0  ┆ 0.571429 ┆ 0.25     ┆ … ┆ 0.406688 ┆ 0.0 ┆ 0.0      ┆ 0         │\n",
       "│ 2023-01-01 00:00:01 ┆ 0.0  ┆ 0.571429 ┆ 0.252001 ┆ … ┆ 0.406691 ┆ 0.0 ┆ 0.0      ┆ 1         │\n",
       "│ 2023-01-01 00:00:02 ┆ 0.0  ┆ 0.571429 ┆ 0.256914 ┆ … ┆ 0.406698 ┆ 0.0 ┆ 0.0      ┆ 2         │\n",
       "│ 2023-01-01 00:00:03 ┆ 0.0  ┆ 0.571429 ┆ 0.268273 ┆ … ┆ 0.40671  ┆ 0.0 ┆ 0.0      ┆ 3         │\n",
       "│ 2023-01-01 00:00:04 ┆ 0.0  ┆ 0.571429 ┆ 0.277953 ┆ … ┆ 0.406726 ┆ 0.0 ┆ 0.0      ┆ 4         │\n",
       "└─────────────────────┴──────┴──────────┴──────────┴───┴──────────┴─────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_rows_list = metadata.rows(named=True)\n",
    "cats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b4cd0e-cacc-4d93-b0e9-a0cdca28b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = cats_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc297da3-97f8-4077-898e-cc23b8c2e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_causes = metadata['root_cause'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8be12f8-8ca1-49a7-81aa-5e05325023a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aimp</th>\n",
       "      <th>amud</th>\n",
       "      <th>arnd</th>\n",
       "      <th>asin1</th>\n",
       "      <th>asin2</th>\n",
       "      <th>adbr</th>\n",
       "      <th>adfl</th>\n",
       "      <th>bed1</th>\n",
       "      <th>bed2</th>\n",
       "      <th>bfo1</th>\n",
       "      <th>bfo2</th>\n",
       "      <th>bso1</th>\n",
       "      <th>bso2</th>\n",
       "      <th>bso3</th>\n",
       "      <th>ced1</th>\n",
       "      <th>cfo1</th>\n",
       "      <th>cso1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409726</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550194</td>\n",
       "      <td>0.406688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.252001</td>\n",
       "      <td>0.50001</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550194</td>\n",
       "      <td>0.406691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.256914</td>\n",
       "      <td>0.50002</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409741</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550195</td>\n",
       "      <td>0.406698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.268273</td>\n",
       "      <td>0.50003</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409758</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550195</td>\n",
       "      <td>0.406710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.277953</td>\n",
       "      <td>0.50004</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409782</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550197</td>\n",
       "      <td>0.406726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aimp      amud      arnd    asin1   asin2  adbr  adfl  \\\n",
       "timestamp                                                                    \n",
       "2023-01-01 00:00:00   0.0  0.571429  0.250000  0.50000  0.5000   0.0   0.0   \n",
       "2023-01-01 00:00:01   0.0  0.571429  0.252001  0.50001  0.5001   0.0   0.0   \n",
       "2023-01-01 00:00:02   0.0  0.571429  0.256914  0.50002  0.5002   0.0   0.0   \n",
       "2023-01-01 00:00:03   0.0  0.571429  0.268273  0.50003  0.5003   0.0   0.0   \n",
       "2023-01-01 00:00:04   0.0  0.571429  0.277953  0.50004  0.5004   0.0   0.0   \n",
       "\n",
       "                        bed1      bed2      bfo1      bfo2      bso1  \\\n",
       "timestamp                                                              \n",
       "2023-01-01 00:00:00  0.33599  0.315382  0.130919  0.116409  0.409726   \n",
       "2023-01-01 00:00:01  0.33599  0.315382  0.130919  0.116409  0.409730   \n",
       "2023-01-01 00:00:02  0.33599  0.315382  0.130919  0.116409  0.409741   \n",
       "2023-01-01 00:00:03  0.33599  0.315382  0.130919  0.116409  0.409758   \n",
       "2023-01-01 00:00:04  0.33599  0.315382  0.130919  0.116409  0.409782   \n",
       "\n",
       "                         bso2     bso3      ced1      cfo1      cso1  \n",
       "timestamp                                                             \n",
       "2023-01-01 00:00:00  0.246024  0.14197  0.112819  0.550194  0.406688  \n",
       "2023-01-01 00:00:01  0.246024  0.14197  0.112819  0.550194  0.406691  \n",
       "2023-01-01 00:00:02  0.246024  0.14197  0.112819  0.550195  0.406698  \n",
       "2023-01-01 00:00:03  0.246024  0.14197  0.112819  0.550195  0.406710  \n",
       "2023-01-01 00:00:04  0.246024  0.14197  0.112819  0.550197  0.406726  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_df=cats_df.set_index('timestamp')\n",
    "cats_df = cats_df.drop(['y','category','entity_id'],axis=1)\n",
    "cats_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b15ba7-0bab-44e8-95aa-c6b534da9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = cats_df[0:1000000]\n",
    "test_df = cats_df[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bda4165-aa93-46ec-909c-19fb14248df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aimp</th>\n",
       "      <th>amud</th>\n",
       "      <th>arnd</th>\n",
       "      <th>asin1</th>\n",
       "      <th>asin2</th>\n",
       "      <th>adbr</th>\n",
       "      <th>adfl</th>\n",
       "      <th>bed1</th>\n",
       "      <th>bed2</th>\n",
       "      <th>bfo1</th>\n",
       "      <th>bfo2</th>\n",
       "      <th>bso1</th>\n",
       "      <th>bso2</th>\n",
       "      <th>bso3</th>\n",
       "      <th>ced1</th>\n",
       "      <th>cfo1</th>\n",
       "      <th>cso1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409726</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550194</td>\n",
       "      <td>0.406688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.252001</td>\n",
       "      <td>0.50001</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550194</td>\n",
       "      <td>0.406691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.256914</td>\n",
       "      <td>0.50002</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409741</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550195</td>\n",
       "      <td>0.406698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.268273</td>\n",
       "      <td>0.50003</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409758</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550195</td>\n",
       "      <td>0.406710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.277953</td>\n",
       "      <td>0.50004</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33599</td>\n",
       "      <td>0.315382</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.116409</td>\n",
       "      <td>0.409782</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.14197</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>0.550197</td>\n",
       "      <td>0.406726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aimp      amud      arnd    asin1   asin2  adbr  adfl  \\\n",
       "timestamp                                                                    \n",
       "2023-01-01 00:00:00   0.0  0.571429  0.250000  0.50000  0.5000   0.0   0.0   \n",
       "2023-01-01 00:00:01   0.0  0.571429  0.252001  0.50001  0.5001   0.0   0.0   \n",
       "2023-01-01 00:00:02   0.0  0.571429  0.256914  0.50002  0.5002   0.0   0.0   \n",
       "2023-01-01 00:00:03   0.0  0.571429  0.268273  0.50003  0.5003   0.0   0.0   \n",
       "2023-01-01 00:00:04   0.0  0.571429  0.277953  0.50004  0.5004   0.0   0.0   \n",
       "\n",
       "                        bed1      bed2      bfo1      bfo2      bso1  \\\n",
       "timestamp                                                              \n",
       "2023-01-01 00:00:00  0.33599  0.315382  0.130919  0.116409  0.409726   \n",
       "2023-01-01 00:00:01  0.33599  0.315382  0.130919  0.116409  0.409730   \n",
       "2023-01-01 00:00:02  0.33599  0.315382  0.130919  0.116409  0.409741   \n",
       "2023-01-01 00:00:03  0.33599  0.315382  0.130919  0.116409  0.409758   \n",
       "2023-01-01 00:00:04  0.33599  0.315382  0.130919  0.116409  0.409782   \n",
       "\n",
       "                         bso2     bso3      ced1      cfo1      cso1  \n",
       "timestamp                                                             \n",
       "2023-01-01 00:00:00  0.246024  0.14197  0.112819  0.550194  0.406688  \n",
       "2023-01-01 00:00:01  0.246024  0.14197  0.112819  0.550194  0.406691  \n",
       "2023-01-01 00:00:02  0.246024  0.14197  0.112819  0.550195  0.406698  \n",
       "2023-01-01 00:00:03  0.246024  0.14197  0.112819  0.550195  0.406710  \n",
       "2023-01-01 00:00:04  0.246024  0.14197  0.112819  0.550197  0.406726  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af75df75-c4c5-47d3-8f48-748b82fc6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ef7544-f092-4051-9ee2-f0894d2a42c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad842ebd-c542-44c1-8dcd-403a591f4877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aimp', 'amud', 'arnd', 'asin1', 'asin2', 'adbr', 'adfl', 'bed1',\n",
       "       'bed2', 'bfo1', 'bfo2', 'bso1', 'bso2', 'bso3', 'ced1', 'cfo1', 'cso1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d4f3cf7-daad-4a4f-849c-7a3bf5dc83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkgnc_data = TKGNGCDataProcessor(train_df,device,num_timestamps=20, lags=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbb4177-4e9d-4049-8b6d-c01fc6d151b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_tkg = PretrainedTKGEmbeddingWithTimestamps(\n",
    "    num_entities=int(tkgnc_data.entity_indices.max().item()+1),\n",
    "    num_relations=int(tkgnc_data.relation_indices.max().item()+1),\n",
    "    embedding_dim=17,\n",
    "    num_timestamps=tkgnc_data.num_timestamps,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f91aab9-1d99-43c3-9784-471a4e0c33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "quads = (\n",
    "    tkgnc_data.entity_indices[:-1],  # Head entities\n",
    "    tkgnc_data.relation_indices,  # Relations\n",
    "    tkgnc_data.entity_indices[1:],  # Tail entities (shifted example)\n",
    "    tkgnc_data.timestamp_indices[:-1],  # Timestamps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5e27acf-c6c2-414e-ba04-414f3dbc7718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pretrained_tkg.pretrain(quads, learning_rate=0.01, epochs=1000)\n",
    "#torch.save(pretrained_tkg.state_dict(), 'pretrained_tkg')\n",
    "pretrained_tkg.load_state_dict(torch.load('pretrained_tkg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e7d528-4b34-4488-86ae-dfa80511c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlowh\\anaconda3\\envs\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CARAT.data_processing import *\n",
    "from CARAT.model import *\n",
    "from CARAT.causal_inference import causal_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab4ff270-6892-43e6-8571-b623acdd105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = train_df.drop('time',axis=1)\n",
    "except:\n",
    "    None\n",
    "try:\n",
    "    test_df = test_df.drop('time',axis=1)\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a25ce54-b18f-421a-9cf8-fd1dce20eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train_df.columns)\n",
    "non_causal_columns = list(set(cols).difference(set(potential_causes)))\n",
    "causal_indices = [train_df.columns.get_loc(col) for col in potential_causes]\n",
    "non_causal_indices = [train_df.columns.get_loc(col) for col in non_causal_columns]\n",
    "\n",
    "num_nodes = len(train_df.columns)\n",
    "\n",
    "new_metadata = []\n",
    "A0 = get_adjacency(cols,causal_indices,non_causal_indices,num_nodes)    \n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model = CausalGraphVAE(input_dim=num_nodes, hidden_dim=128,\n",
    "                   latent_dim=16, \n",
    "                   num_nodes=num_nodes, \n",
    "                   embed_dim=17,\n",
    "                   prior_adj_matrix=A0.to(torch.float))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f85455-f1f0-4274-8987-871b4d279b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0\n",
      "Epoch 0, Loss: 0.0004\n",
      "Epoch 0: Average Loss = 245.5344, Best Loss = 245.5344\n",
      "Epoch 100: Average Loss = 42.5929, Best Loss = 42.4835\n",
      "Epoch 200: Average Loss = 35.7108, Best Loss = 35.7108\n",
      "Early stopping triggered after 275 epochs. Restoring best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting causal mechanism of node cso1: 100%|██████████| 17/17 [00:01<00:00, 13.52it/s]\n",
      "Evaluating set functions...: 100%|██████████| 151/151 [00:01<00:00, 80.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT CAUSE FOUND!\n",
      "bso3-->bfo1 | bso3 | bfo2\n",
      "Model Accuracy: 100.0%\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "Model: 1\n",
      "Epoch 0, Loss: 0.0015\n",
      "Epoch 0: Average Loss = 207.1768, Best Loss = 207.1768\n",
      "Epoch 100: Average Loss = 33.6059, Best Loss = 33.5947\n",
      "Early stopping triggered after 149 epochs. Restoring best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting causal mechanism of node cso1: 100%|██████████| 17/17 [00:01<00:00,  8.54it/s]\n",
      "Evaluating set functions...: 100%|██████████| 112/112 [00:00<00:00, 729.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT CAUSE FOUND!\n",
      "bso3-->bfo1 | bso1 | bso3\n",
      "Model Accuracy: 100.0%\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "Model: 2\n",
      "Epoch 0, Loss: 0.0005\n",
      "Epoch 0: Average Loss = 309.0756, Best Loss = 309.0756\n",
      "Epoch 100: Average Loss = 36.0679, Best Loss = 35.8804\n",
      "Epoch 200: Average Loss = 31.7616, Best Loss = 31.6003\n",
      "Early stopping triggered after 259 epochs. Restoring best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting causal mechanism of node cso1: 100%|██████████| 17/17 [00:01<00:00,  9.22it/s]\n",
      "Evaluating set functions...: 100%|██████████| 114/114 [00:00<00:00, 573.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT CAUSE FOUND!\n",
      "bfo2-->bso3 | bfo1 | bfo2\n",
      "Model Accuracy: 100.0%\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "Model: 3\n",
      "Epoch 0, Loss: 0.0003\n",
      "Epoch 0: Average Loss = 261.7169, Best Loss = 261.7169\n",
      "Epoch 100: Average Loss = 47.3148, Best Loss = 47.3148\n",
      "Epoch 200: Average Loss = 31.1169, Best Loss = 31.1169\n",
      "Epoch 300: Average Loss = 24.9325, Best Loss = 24.9325\n",
      "Epoch 400: Average Loss = 21.6484, Best Loss = 21.5521\n",
      "Early stopping triggered after 416 epochs. Restoring best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting causal mechanism of node cso1: 100%|██████████| 17/17 [00:00<00:00, 26.46it/s]\n",
      "Evaluating set functions...: 100%|██████████| 51/51 [00:00<00:00, 25495.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT CAUSE FOUND!\n",
      "bed2-->bfo2 | bfo1 | bed2\n",
      "Model Accuracy: 100.0%\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "Model: 4\n",
      "Epoch 0, Loss: 0.0001\n",
      "Epoch 0: Average Loss = 240.3892, Best Loss = 240.3892\n",
      "Epoch 100: Average Loss = 50.6195, Best Loss = 50.6195\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import set_seed\n",
    "set_seed()\n",
    "n_correct = 0\n",
    "total_checked = 0\n",
    "for i, row in enumerate(cats_rows_list):\n",
    "    total_checked +=1 \n",
    "    print('Model: '+ str(i))\n",
    "    anomaly = eval(row['affected'])[0]\n",
    "\n",
    "    anomaly_time = datetime.strptime(row['start_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    #start_time = datetime.strptime(row['start_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time = datetime.strptime(row['end_time'],\"%Y-%m-%d %H:%M:%S\")\n",
    "    root_cause = row['root_cause']\n",
    "    mod_df = test_df[(test_df.index>= anomaly_time) & (test_df.index<= end_time)]\n",
    "    mod_df = mod_df[['aimp', 'amud', 'arnd', 'asin1', 'asin2', 'adbr', 'adfl', 'bed1',\n",
    "       'bed2', 'bfo1', 'bfo2', 'bso1', 'bso2', 'bso3', 'ced1', 'cfo1', 'cso1']]\n",
    "    num_nodes = len(mod_df.columns)\n",
    "\n",
    "    start_len = mod_df.shape[0]\n",
    "    if start_len >1000:\n",
    "        start_len = 1000\n",
    "\n",
    "    start_time = anomaly_time- timedelta(seconds=start_len)\n",
    "\n",
    "    normal_df = test_df[(test_df.index>= start_time) & (test_df.index< anomaly_time)]\n",
    "\n",
    "    sample_data = TKGNGCDataProcessor(mod_df,device,num_timestamps=20, lags=1)\n",
    "    model_data = create_granger_gat_data(pretrained_tkg,sample_data)\n",
    "    model_data.retrain_tkg()\n",
    "    features = model_data.time_series_data\n",
    "    model_name = 'model_category_'+str(row['category'])\n",
    "    \"\"\"model = CausalGraphVAE(input_dim=num_nodes, hidden_dim=128,\n",
    "                   latent_dim=16, \n",
    "                   num_nodes=num_nodes, \n",
    "                   embed_dim=17,\n",
    "                   prior_adj_matrix=A0.to(torch.float))\"\"\"\n",
    "    model = CausalGraphVAE(input_dim=num_nodes, hidden_dim=128,\n",
    "                   latent_dim=16, \n",
    "                   num_nodes=num_nodes, \n",
    "                   embed_dim=17,\n",
    "                   prior_adj_matrix=A0.to(torch.float))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    data = create_lagged_features(features, 3, pad_value=0)\n",
    "    ee = create_lagged_features(model_data.entity_emb, 3, pad_value=0)\n",
    "    tt = create_lagged_features(model_data.timestamp_emb, 3, pad_value=0)\n",
    "        \n",
    "    dataset = TimeSeriesDataset(data, ee, tt)\n",
    "    dataloader = DataLoader(dataset,batch_size = BATCH_SIZE, shuffle=False)\n",
    "    loss = train_causal_vae(model, optimizer, dataloader, A0, num_epochs=1000)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, _, _, learned_adj_matrix = model(data,ee,tt, num_nodes=num_nodes)\n",
    "        causal_graph = learned_adj_matrix.cpu().numpy()\n",
    "\n",
    "\n",
    "    adj_data = pd.DataFrame(causal_graph,index=cols,columns=cols)\n",
    "    candidates = adj_data[anomaly].sort_values(ascending=False)\n",
    "    candidates = candidates[candidates.index.isin( potential_causes)]\n",
    "    #A0 = learned_adj_matrix\n",
    "    try:\n",
    "        ci = causal_inference(causal_graph, mod_df, normal_df)\n",
    "        ci.infer_causal_path(anomaly)  \n",
    "\n",
    "        if len(ci.causal_factors) >= 3:\n",
    "            potential_cause1 = ci.causal_factors[0][0]\n",
    "            potential_cause2 = ci.causal_factors[1][0]\n",
    "            potential_cause3 = ci.causal_factors[2][0]\n",
    "        elif len(ci.causal_factors) == 2:\n",
    "            potential_cause1 = ci.causal_factors[0][0]\n",
    "            potential_cause2 = ci.causal_factors[1][0]\n",
    "            potential_cause3 = 'NA'\n",
    "        elif len(ci.causal_factors) == 1:\n",
    "            potential_cause1 = ci.causal_factors[0][0]\n",
    "            potential_cause2 = \"NA\"\n",
    "            potential_cause3 = 'NA'\n",
    "        else:\n",
    "            potential_cause1 = candidates.index[0]\n",
    "            potential_cause2 = candidates.index[1]\n",
    "            potential_cause3 = candidates.index[2]\n",
    "    except:\n",
    "        potential_cause1 = candidates.index[0]\n",
    "        potential_cause2 = candidates.index[1]\n",
    "        potential_cause3 = candidates.index[2]\n",
    "\n",
    "   \n",
    "    if root_cause in [potential_cause1,potential_cause2,potential_cause3]:\n",
    "        n_correct+=1\n",
    "\n",
    "    if root_cause == potential_cause1:\n",
    "        row['cause_1'] = 1\n",
    "    if root_cause == potential_cause2:\n",
    "        row['cause_2'] = 1\n",
    "    if root_cause == potential_cause3:\n",
    "        row['cause_3'] = 1\n",
    "    new_metadata.append(row)\n",
    "    if root_cause in [potential_cause1 , potential_cause2 , potential_cause3]:\n",
    "        print('ROOT CAUSE FOUND!')\n",
    "    print(root_cause + '-->' + potential_cause1 + ' | ' + potential_cause2 + ' | ' + potential_cause3)\n",
    "\n",
    "    print(\"Model Accuracy: \" + str(round( (n_correct/total_checked)*100,2)) + '%' )\n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94cb8784-41f3-4afa-8c55-84b366f27049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.465"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pl.DataFrame(new_metadata)\n",
    "agg_stats = stats.select(pl.sum(\"cause_1\", \"cause_2\",'cause_3'))\n",
    "agg_stats.select(pl.sum_horizontal(pl.all())).item()/stats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "896fe9f8-fef6-4d4d-af75-2581bfdcd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "prior_adj_matrix = A0.to(device).double()  # Move prior_adj_matrix to device\n",
    "num_epochs = 50\n",
    "best_loss = float(\"inf\")  # Initialize best loss as infinity\n",
    "best_model_state = None  # To store best model parameters\n",
    "epochs_no_improve = 0  # Counter for early stopping\n",
    "loss_history = []  # Store epoch losses\n",
    "batch_loss_history = []  # Store all batch losses\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    batch_losses = []  # Store losses per batch\n",
    "\n",
    "    for batch_idx, (x_batch, entity_batch, time_batch) in enumerate(dataloader):\n",
    "        if x_batch.shape[0]<=x_batch.shape[1]:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to correct device and convert to float64\n",
    "        x_batch = x_batch.to(device).double()\n",
    "        entity_batch = entity_batch.to(device).double()\n",
    "        time_batch = time_batch.to(device).double()\n",
    "        break\n",
    "\n",
    "        # Forward pass\n",
    "        recon_x, mu, logvar, adj_matrix = model(x_batch, entity_batch, time_batch, num_nodes=x_batch.shape[1])\n",
    "\n",
    "        # Compute loss\n",
    "        loss = causal_vae_loss(\n",
    "            recon_x.double(), x_batch, mu.double(), logvar.double(), adj_matrix.double(), prior_adj_matrix.double()\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "            print(\"NaN or Inf detected in loss function!\")\n",
    "            print(f\"Recon loss: {recon_loss}, KL loss: {kl_loss}, Sparsity loss: {sparsity_loss}, Acyclicity loss: {acyclicity_loss}, Attention loss: {attention_loss}\")\n",
    "            exit(1)\n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batch_losses.append(loss.item())  # Store batch loss\n",
    "\n",
    "    break\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)  # Calculate average loss per epoch\n",
    "    loss_history.append(avg_loss)  # Store epoch loss\n",
    "    batch_loss_history.append(batch_losses)  # Store batch losses\n",
    "\n",
    "    # Check if loss improved\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        best_model_state = copy.deepcopy(model.state_dict())  # Save best model\n",
    "        epochs_no_improve = 0  # Reset counter\n",
    "    else:\n",
    "        epochs_no_improve += 1  # Increment counter if no improvement\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Average Loss = {avg_loss:.4f}, Best Loss = {best_loss:.4f}\")\n",
    "\n",
    "    # Early stopping condition\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch} epochs. Restoring best model.\")\n",
    "        model.load_state_dict(best_model_state)  # Restore best model state\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76cf5a6e-7860-4734-a574-e7300e690767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "from CARAT.utils import TGCN, A3TGCN\n",
    "import copy\n",
    "from utils.utils import set_seed\n",
    "set_seed()\n",
    "\n",
    "# Automatically select GPU if available, otherwise use CPU\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class GraphLearningModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns an adjacency matrix with Graph Attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, hidden_dim, prior_adj_matrix=None, attention_heads=4):\n",
    "        super(GraphLearningModule, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.attention_heads = attention_heads\n",
    "\n",
    "        # Learnable adjacency matrix (Move to device)\n",
    "        self.edge_score = nn.Parameter(torch.randn(num_nodes, num_nodes, dtype=torch.float64, device=device))\n",
    "\n",
    "        # Prior adjacency matrix (Move to device)\n",
    "        if prior_adj_matrix is not None:\n",
    "            self.prior_adj = torch.tensor(prior_adj_matrix, dtype=torch.float64, device=device)\n",
    "        else:\n",
    "            self.prior_adj = torch.zeros(num_nodes, num_nodes, dtype=torch.float64, device=device)\n",
    "\n",
    "    def forward(self):\n",
    "        adj_matrix = torch.sigmoid(self.edge_score) + self.prior_adj\n",
    "        adj_matrix = torch.clamp(adj_matrix, 0, 1)\n",
    "    \n",
    "        # Convert adjacency matrix to sparse format\n",
    "        edge_index, edge_weights = dense_to_sparse(adj_matrix)\n",
    "    \n",
    "        # Get the true number of nodes (max node index + 1)\n",
    "        actual_num_nodes = edge_index.max().item() + 1\n",
    "    \n",
    "        # Ensure all indices are within bounds\n",
    "        valid_mask = (edge_index[0] < actual_num_nodes) & (edge_index[1] < actual_num_nodes)\n",
    "        edge_index = edge_index[:, valid_mask]\n",
    "        edge_weights = edge_weights[valid_mask]\n",
    "    \n",
    "        #print(f\"GraphLearningModule Output: edge_index max {edge_index.max()}, expected num_nodes {actual_num_nodes}\")\n",
    "    \n",
    "        return edge_index.to(device).long(), edge_weights.to(device).double()\n",
    "    \n",
    "            \n",
    "\n",
    "class CausalGraphVAE(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, latent_dim, num_nodes, prior_adj_matrix=None, attention_heads=4):\n",
    "        super(CausalGraphVAE, self).__init__()\n",
    "\n",
    "        # Graph Learning with Attention (Move to device)\n",
    "        self.graph_learner = GraphLearningModule(num_nodes, hidden_dim, prior_adj_matrix, attention_heads).to(device)\n",
    "\n",
    "        # Embedding layers for additional inputs\n",
    "        self.entity_embed_layer = nn.Linear(embed_dim, hidden_dim, dtype=torch.float64).to(device)\n",
    "        self.timestamp_embed_layer = nn.Linear(embed_dim, hidden_dim, dtype=torch.float64).to(device)\n",
    "\n",
    "        # Temporal Graph ConvolutionalNetwork\n",
    "        self.tgcn1 = A3TGCN(input_dim + 2 * hidden_dim, hidden_dim,periods=3).to(device).double()\n",
    "        self.tgcn2 = A3TGCN(hidden_dim, hidden_dim,periods=3).to(device).double()\n",
    "\n",
    "        # Latent Space\n",
    "        self.mu_layer = nn.Linear(hidden_dim, latent_dim, dtype=torch.float64).to(device)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim, latent_dim, dtype=torch.float64).to(device)\n",
    "\n",
    "        # Decoder with Temporal Graph ConvolutionalNetwork\n",
    "        self.decoder_fc = nn.Linear(latent_dim, hidden_dim, dtype=torch.float64).to(device)\n",
    "        self.tgcn_decoder = TGCN(hidden_dim, input_dim).to(device).double()\n",
    "\n",
    "    def encode(self, x, entity_emb, time_emb, edge_index, edge_weights):\n",
    "        \"\"\"\n",
    "        Encoding with concatenation of entity and timestamp embeddings.\n",
    "        \"\"\"\n",
    "        # Move inputs to correct device and convert to float64\n",
    "        x = x.to(device).double()\n",
    "        entity_emb = entity_emb.to(device).double()\n",
    "        time_emb = time_emb.to(device).double()\n",
    "        edge_index = edge_index.to(device).long()\n",
    "        edge_weights = edge_weights.to(device).double()\n",
    "\n",
    "        # Transform entity & timestamp embeddings\n",
    "        entity_emb = F.relu(self.entity_embed_layer(entity_emb))\n",
    "        time_emb = F.relu(self.timestamp_embed_layer(time_emb))\n",
    "\n",
    "        # Concatenate embeddings with raw features\n",
    "        x = torch.cat([x, entity_emb, time_emb], dim=-1)\n",
    "\n",
    "        # Temporal Graph Convolutional Network Encoding (Pass edge_index dynamically)\n",
    "        x = F.relu(self.tgcn1(x, edge_index, edge_weights))\n",
    "       # x = F.relu(self.tgcn2(x, edge_index, edge_weights))\n",
    "\n",
    "        mu = self.mu_layer(x)\n",
    "        logvar = self.logvar_layer(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std, device=device, dtype=torch.float64)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, edge_index, edge_weights, num_nodes):\n",
    "        \"\"\"\n",
    "        Decodes the learned representation back to the original space.\n",
    "        \"\"\"\n",
    "        x = self.decoder_fc(z)\n",
    "        x = F.relu(self.tgcn_decoder(x, edge_index, edge_weights))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, entity_emb, time_emb, num_nodes):\n",
    "        edge_index, edge_weights = self.graph_learner()\n",
    "        \n",
    "        actual_num_nodes = x.shape[2]  # Ensure alignment\n",
    "        if edge_index.max() >= actual_num_nodes:\n",
    "            raise ValueError(f\"Invalid edge_index detected in CausalGraphVAE! Max index: {edge_index.max()}, Expected < {actual_num_nodes}\")\n",
    "    \n",
    "        mu, logvar = self.encode(x, entity_emb, time_emb, edge_index, edge_weights)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, edge_index, edge_weights, actual_num_nodes)  # Pass correct num_nodes\n",
    "    \n",
    "        return recon_x, mu, logvar, edge_weights.view(actual_num_nodes, actual_num_nodes)\n",
    "\n",
    "\n",
    "def causal_vae_loss(recon_x, x, mu, logvar, adj_matrix, prior_adj_matrix, \n",
    "                    lambda_sparsity=1e-3, lambda_acyclic=1e-2, lambda_attention=1e-2):\n",
    "    \"\"\"\n",
    "    Computes the loss function for the Causal Graph VAE with attention.\n",
    "    \"\"\"\n",
    "    # Move all tensors to the correct device and convert to float64\n",
    "    recon_x = recon_x.to(device).double()\n",
    "    x = x.to(device).double()\n",
    "    mu = mu.to(device).double()\n",
    "    logvar = logvar.to(device).double()\n",
    "    adj_matrix = adj_matrix.to(device).double()\n",
    "    prior_adj_matrix = prior_adj_matrix.to(device).double()\n",
    "\n",
    "    # Reconstruction loss\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "\n",
    "    # KL Divergence loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Graph Sparsity loss (L1 regularization)\n",
    "    sparsity_loss = lambda_sparsity * torch.norm(adj_matrix, p=1)\n",
    "\n",
    "    # Acyclicity Constraint (Ensures DAG structure)\n",
    "    eye_matrix = torch.eye(adj_matrix.shape[0], dtype=torch.float64, device=device)  # Fix: Ensure eye_matrix is float64\n",
    "    H = torch.matrix_exp(adj_matrix * adj_matrix)  # Exponentiate the adjacency matrix\n",
    "    acyclicity_loss = lambda_acyclic * torch.trace(H - eye_matrix)\n",
    "\n",
    "    # Attention-based Causal Alignment Loss\n",
    "    attention_loss = lambda_attention * F.mse_loss(adj_matrix, prior_adj_matrix)\n",
    "\n",
    "    # Compute total loss\n",
    "    total_loss = recon_loss + kl_loss + sparsity_loss + acyclicity_loss + attention_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def train_causal_vae(model, optimizer, dataloader, prior_adj_matrix, num_epochs=100, patience=10):\n",
    "    model.train()\n",
    "    prior_adj_matrix = prior_adj_matrix.to(device).double()  # Move prior_adj_matrix to device\n",
    "\n",
    "    best_loss = float(\"inf\")  # Initialize best loss as infinity\n",
    "    best_model_state = None  # To store best model parameters\n",
    "    epochs_no_improve = 0  # Counter for early stopping\n",
    "    loss_history = []  # Store epoch losses\n",
    "    batch_loss_history = []  # Store all batch losses\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        batch_losses = []  # Store losses per batch\n",
    "\n",
    "        for batch_idx, (x_batch, entity_batch, time_batch) in enumerate(dataloader):\n",
    "            if x_batch.shape[0]<=x_batch.shape[1]:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move data to correct device and convert to float64\n",
    "            x_batch = x_batch.to(device).double()\n",
    "            entity_batch = entity_batch.to(device).double()\n",
    "            time_batch = time_batch.to(device).double()\n",
    "\n",
    "            # Forward pass\n",
    "            recon_x, mu, logvar, adj_matrix = model(x_batch, entity_batch, time_batch, num_nodes=x_batch.shape[1])\n",
    "\n",
    "            # Compute loss\n",
    "            loss = causal_vae_loss(\n",
    "                recon_x.double(), x_batch, mu.double(), logvar.double(), adj_matrix.double(), prior_adj_matrix.double()\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                print(\"NaN or Inf detected in loss function!\")\n",
    "                print(f\"Recon loss: {recon_loss}, KL loss: {kl_loss}, Sparsity loss: {sparsity_loss}, Acyclicity loss: {acyclicity_loss}, Attention loss: {attention_loss}\")\n",
    "                exit(1)\n",
    "\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batch_losses.append(loss.item())  # Store batch loss\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)  # Calculate average loss per epoch\n",
    "        loss_history.append(avg_loss)  # Store epoch loss\n",
    "        batch_loss_history.append(batch_losses)  # Store batch losses\n",
    "\n",
    "        # Check if loss improved\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())  # Save best model\n",
    "            epochs_no_improve = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_no_improve += 1  # Increment counter if no improvement\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Average Loss = {avg_loss:.4f}, Best Loss = {best_loss:.4f}\")\n",
    "\n",
    "        # Early stopping condition\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs. Restoring best model.\")\n",
    "            model.load_state_dict(best_model_state)  # Restore best model state\n",
    "            break\n",
    "\n",
    "    return loss_history  # Return trained model, epoch losses, and batch losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfd822e-a432-4019-91b0-3cc45b51145b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m recon_x, mu, logvar, adj_matrix \u001b[38;5;241m=\u001b[39m model(x_batch, entity_batch, time_batch, num_nodes\u001b[38;5;241m=\u001b[39mx_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m loss \u001b[38;5;241m=\u001b[39m causal_vae_loss(\n\u001b[0;32m     35\u001b[0m     recon_x\u001b[38;5;241m.\u001b[39mdouble(), x_batch, mu\u001b[38;5;241m.\u001b[39mdouble(), logvar\u001b[38;5;241m.\u001b[39mdouble(), adj_matrix\u001b[38;5;241m.\u001b[39mdouble(), prior_adj_matrix\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[0;32m     36\u001b[0m )\n",
      "Cell \u001b[1;32mIn[23], line 148\u001b[0m, in \u001b[0;36mcausal_vae_loss\u001b[1;34m(recon_x, x, mu, logvar, adj_matrix, prior_adj_matrix, lambda_sparsity, lambda_acyclic, lambda_attention)\u001b[0m\n\u001b[0;32m    145\u001b[0m prior_adj_matrix \u001b[38;5;241m=\u001b[39m prior_adj_matrix\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Reconstruction loss\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m recon_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(recon_x, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# KL Divergence loss\u001b[39;00m\n\u001b[0;32m    151\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m logvar \u001b[38;5;241m-\u001b[39m mu\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m logvar\u001b[38;5;241m.\u001b[39mexp())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\functional.py:3791\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[0;32m   3793\u001b[0m     expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3794\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "prior_adj_matrix = A0\n",
    "num_epochs=100\n",
    "patience=10\n",
    "\n",
    "\n",
    "model.train()\n",
    "prior_adj_matrix = prior_adj_matrix.to(device).double()  # Move prior_adj_matrix to device\n",
    "\n",
    "best_loss = float(\"inf\")  # Initialize best loss as infinity\n",
    "best_model_state = None  # To store best model parameters\n",
    "epochs_no_improve = 0  # Counter for early stopping\n",
    "loss_history = []  # Store epoch losses\n",
    "batch_loss_history = []  # Store all batch losses\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    batch_losses = []  # Store losses per batch\n",
    "\n",
    "    for batch_idx, (x_batch, entity_batch, time_batch) in enumerate(dataloader):\n",
    "        if x_batch.shape[0]<=x_batch.shape[1]:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to correct device and convert to float64\n",
    "        x_batch = x_batch.to(device).double()\n",
    "        entity_batch = entity_batch.to(device).double()\n",
    "        time_batch = time_batch.to(device).double()\n",
    "\n",
    "        # Forward pass\n",
    "        recon_x, mu, logvar, adj_matrix = model(x_batch, entity_batch, time_batch, num_nodes=x_batch.shape[1])\n",
    "\n",
    "        # Compute loss\n",
    "        loss = causal_vae_loss(\n",
    "            recon_x.double(), x_batch, mu.double(), logvar.double(), adj_matrix.double(), prior_adj_matrix.double()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ac142c5-43cd-4362-b58f-c88a56fd18ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecee88-c441-4c70-ba7c-46a0f3dd421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_x = recon_x.to(device).double()\n",
    "x = x.to(device).double()\n",
    "mu = mu.to(device).double()\n",
    "logvar = logvar.to(device).double()\n",
    "adj_matrix = adj_matrix.to(device).double()\n",
    "prior_adj_matrix = prior_adj_matrix.to(device).double()\n",
    "\n",
    "# Reconstruction loss\n",
    "recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "\n",
    "# KL Divergence loss\n",
    "kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "# Graph Sparsity loss (L1 regularization)\n",
    "sparsity_loss = lambda_sparsity * torch.norm(adj_matrix, p=1)\n",
    "\n",
    "# Acyclicity Constraint (Ensures DAG structure)\n",
    "eye_matrix = torch.eye(adj_matrix.shape[0], dtype=torch.float64, device=device)  # Fix: Ensure eye_matrix is float64\n",
    "H = torch.matrix_exp(adj_matrix * adj_matrix)  # Exponentiate the adjacency matrix\n",
    "acyclicity_loss = lambda_acyclic * torch.trace(H - eye_matrix)\n",
    "\n",
    "# Attention-based Causal Alignment Loss\n",
    "attention_loss = lambda_attention * F.mse_loss(adj_matrix, prior_adj_matrix)\n",
    "\n",
    "# Compute total loss\n",
    "total_loss = recon_loss + kl_loss + sparsity_loss + acyclicity_loss + attention_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606f93ca-3af9-4fa6-9c51-02685a9caa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 17])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52e2f247-5026-4ad5-919b-cbeb587cacdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 17])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14495149-5914-4202-bcd7-b27baaf2436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=num_nodes\n",
    "hidden_dim=128\n",
    "latent_dim=16\n",
    "embed_dim=17\n",
    "prior_adj_matrix=A0.to(torch.float)\n",
    "attention_heads=4\n",
    "ema_decay=0.9\n",
    "\n",
    "\n",
    "graph_learner = GraphLearningModule(num_nodes, hidden_dim, prior_adj_matrix, attention_heads).to(device)\n",
    "\n",
    "# Embedding layers\n",
    "entity_embed_layer = nn.Linear(embed_dim, hidden_dim, dtype=torch.float64).to(device)\n",
    "timestamp_embed_layer = nn.Linear(embed_dim, hidden_dim, dtype=torch.float64).to(device)\n",
    "\n",
    "# Temporal Graph Convolutional Network\n",
    "tgcn1 = A3TGCN(input_dim + 2 * hidden_dim, hidden_dim,periods=3).to(device).double()\n",
    "tgcn2 = A3TGCN(hidden_dim, hidden_dim,periods=3).to(device).double()\n",
    "\n",
    "# Graph-GRU for Temporal State Retention\n",
    "graph_memory = nn.GRU(hidden_dim, hidden_dim, batch_first=False).to(device).double()\n",
    "\n",
    "# Latent Space\n",
    "mu_layer = nn.Linear(hidden_dim, latent_dim, dtype=torch.float64).to(device)\n",
    "logvar_layer = nn.Linear(hidden_dim, latent_dim, dtype=torch.float64).to(device)\n",
    "\n",
    "# Decoder\n",
    "decoder_fc = nn.Linear(latent_dim, hidden_dim,dtype=torch.float64).to(device)\n",
    "tgcn_decoder = TGCN(hidden_dim, input_dim).to(device).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b81196eb-a1a4-4dce-9fc3-1ca2964cc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_weights = graph_learner()\n",
    "x = x_batch.to(device).double()\n",
    "entity_emb = entity_batch.to(device).double()\n",
    "time_emb = time_batch.to(device).double()\n",
    "edge_index = edge_index.to(device).long()\n",
    "edge_weights = edge_weights.to(device).double()\n",
    "\n",
    "# Transform entity & timestamp embeddings\n",
    "entity_emb = F.relu(entity_embed_layer(entity_emb))\n",
    "time_emb = F.relu(timestamp_embed_layer(time_emb))\n",
    "\n",
    "# Concatenate embeddings with raw features\n",
    "x = torch.cat([x, entity_emb, time_emb], dim=-1)\n",
    "\n",
    "# Temporal Graph Convolutional Network Encoding (Pass edge_index dynamically)\n",
    "x = F.relu(tgcn1(x, edge_index, edge_weights))\n",
    "#x = F.relu(tgcn2(x, edge_index, edge_weights))\n",
    "\n",
    "mu = mu_layer(x)\n",
    "logvar = logvar_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6059bdb-ea1d-44cd-b51f-9533f9ed95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize( mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std, device=device, dtype=torch.float64)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cda6766e-1d59-4feb-8713-a35baed51f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = reparameterize(mu, logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4fae7b8-12fe-4bd0-8fdf-d9e919161661",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = decoder_fc(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8fb23f5-daca-45dd-8568-7fe978cf5247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "420413e5-8609-471a-8a6c-9655056b2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(tgcn_decoder(x, edge_index, edge_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70bfe45-0fce-4f70-be6a-3f26da572b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d874c-477d-4bcc-b347-f35b80413306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e545b7c2-1897-4075-9a65-9b14664f0213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7049, 0.5933, 0.3940])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "in_channels = input_dim\n",
    "out_channels = 2 * hidden_dim\n",
    "periods = 3\n",
    "improved= False\n",
    "cached = False\n",
    "add_self_loops = True\n",
    "\n",
    "\n",
    "_base_tgcn = TGCN(\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    improved=improved,\n",
    "    cached=cached,\n",
    "    add_self_loops=add_self_loops,\n",
    "\n",
    ").to(device)\n",
    "device = torch.device('cpu')\n",
    "_attention = torch.empty(periods, device=device)\n",
    "torch.nn.init.uniform_(_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00e46bd1-ef77-4341-bbaf-b142582326ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(_attention, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m period \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     H_accum \u001b[38;5;241m=\u001b[39m H_accum \u001b[38;5;241m+\u001b[39m probs[period] \u001b[38;5;241m*\u001b[39m _base_tgcn(\n\u001b[0;32m     10\u001b[0m         X[:, period, :], edge_index, edge_weight, H\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m#X[:, period, :], edge_index, edge_weight, H\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\praxis_research\\esce\\CARAT\\utils.py:216\u001b[0m, in \u001b[0;36mTGCN.forward\u001b[1;34m(self, X, edge_index, edge_weight, H)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03mMaking a forward pass. If edge weights are not present the forward pass\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03mdefaults to an unweighted graph. If the hidden state matrix is not present\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    215\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_hidden_state(X, H)\n\u001b[1;32m--> 216\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_update_gate(X, edge_index, edge_weight, H)\n\u001b[0;32m    217\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_reset_gate(X, edge_index, edge_weight, H)\n\u001b[0;32m    218\u001b[0m H_tilde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\praxis_research\\esce\\CARAT\\utils.py:173\u001b[0m, in \u001b[0;36mTGCN._calculate_update_gate\u001b[1;34m(self, X, edge_index, edge_weight, H)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_update_gate\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index, edge_weight, H):\n\u001b[1;32m--> 173\u001b[0m     Z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_z(X, edge_index, edge_weight), H], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    174\u001b[0m     Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_z(Z)\n\u001b[0;32m    175\u001b[0m     Z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(Z)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "X = x.to(device)\n",
    "H = hidden_state.to(device)\n",
    "edge_weight=edge_weights.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "\n",
    "H_accum = 0\n",
    "probs = torch.nn.functional.softmax(_attention, dim=0).to(device)\n",
    "for period in range(3):\n",
    "    H_accum = H_accum + probs[period] * _base_tgcn(\n",
    "        X[:, period, :], edge_index, edge_weight, H\n",
    "        #X[:, period, :], edge_index, edge_weight, H\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99b53543-11dd-417f-8ad1-ef2a671d72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = _base_tgcn._set_hidden_state(X[:, period,:], H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "822a3788-c4d2-49d8-b2f5-31641157da19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e572dc9e-7898-491f-9246-b6776adcc88e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Z \u001b[38;5;241m=\u001b[39m _base_tgcn\u001b[38;5;241m.\u001b[39m_calculate_update_gate(X[:, period,:], edge_index, edge_weight, H)\n",
      "File \u001b[1;32m~\\Documents\\Doctorate\\praxis_research\\praxis_research\\esce\\CARAT\\utils.py:173\u001b[0m, in \u001b[0;36mTGCN._calculate_update_gate\u001b[1;34m(self, X, edge_index, edge_weight, H)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_update_gate\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index, edge_weight, H):\n\u001b[1;32m--> 173\u001b[0m     Z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_z(X, edge_index, edge_weight), H], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    174\u001b[0m     Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_z(Z)\n\u001b[0;32m    175\u001b[0m     Z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(Z)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "Z = _base_tgcn._calculate_update_gate(X[:, period,:], edge_index, edge_weight, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a49298f6-560b-4e40-a890-55ba9cd57b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "conv_z = GCNConv(\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    improved=improved,\n",
    "    cached=cached,\n",
    "    add_self_loops=add_self_loops,\n",
    ")\n",
    "\n",
    "linear_z = torch.nn.Linear(2 * out_channels, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0932bcd0-5e8b-43b5-8c69-4a1ed0bb8174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 17])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(X[:,period,:],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f2f94d8-6c0e-4255-92a3-1484179f8f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73019db2-b92a-4c60-8dea-3cee6b26af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.cat([conv_z(torch.unsqueeze(X[:,period,:],0), edge_index, edge_weight), H], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86ee8109-aac3-4b20-a718-ba044930a06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 384])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f90c010-dbad-4ab9-bc53-846a037223ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x384 and 512x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Z \u001b[38;5;241m=\u001b[39m linear_z(Z)\n\u001b[0;32m      2\u001b[0m Z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(Z)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x384 and 512x256)"
     ]
    }
   ],
   "source": [
    "\n",
    "Z = linear_z(Z)\n",
    "Z = torch.sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d6c09-c630-4703-990d-2a8db8841cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = self._set_hidden_state(X, H)\n",
    "Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "H = self._calculate_hidden_state(Z, H, H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa34f92-ca3e-4e05-84c6-dfbcae718809",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved = False\n",
    "cached = False\n",
    "add_self_loops= True\n",
    "\n",
    "\n",
    " def _create_update_gate_parameters_and_layers():\n",
    "\n",
    "        conv_z = GCNConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            improved=improved,\n",
    "            cached=cached,\n",
    "            add_self_loops=add_self_loops,\n",
    "        )\n",
    "\n",
    "        linear_z = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_r = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_r = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_h = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_h = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
    "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], axis=1)\n",
    "        Z = self.linear_z(Z)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], axis=1)\n",
    "        R = self.linear_r(R)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = torch.cat([self.conv_h(X, edge_index, edge_weight), H * R], axis=1)\n",
    "        H_tilde = self.linear_h(H_tilde)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07c1a7-22da-4c43-96e7-720a5f488247",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde)\n",
    "        return H"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
